Better coding:
    - Refactor 'kaggle.py' to be more general
    - Use constants throughout all code for the data files (stop using the strings)
    - Automatic creation of data/corpus.txt

Things to consider:

- Uni/bi-grams: 
    - Different corpus?
    - Different ordering of words for feature selection (i.e., instead of raw frequency)
    - Better filtering of non-relevant words? (i.e., get rid of stop words, etc.)
    - Check out better tokenization :: nltk.download() will get us nltk.data.load('tokenizers/punkt/english.pickle')
- How to build a more general model using all of the entry sets, and not just learning on each set?

Try modeling individual graders
fix kaggle.py to be better

DATA EXPLORATION TODOs:
- output ranked in order of how badly we predict
- look at distribution of scores/grades
- Look at x/y plot of projected 1-dimensional feature vs grades for each grader

Learning ideas:

TODO:
take command line parameter options a la svm light
tune parameters
do I need to update w for even the pairs of points with zero slack?

Ideas:
normalize the features
cross validation framework to set SVM parameters. specify validation set, svm tries a few parameter settings and picks the best one on the validation data
non-linear kernel
numerical optimization of learning: save last 3 parameter vectors and objective scores, take a quadratic Newton-descent type step
when stochastic gradient descent is close to convergence, switch to a few iterations of gradient descent? newton's method?
anneal eta down to 0 as we converge

do feature selection by essay set

