Soon:
 - put unigrams back in - but instead do feature selection through the top 5 words in top X topics.

Better coding:
    - Refactor 'kaggle.py' to be more general
    - Use constants throughout all code for the data files (stop using the strings)
    - Automatic creation of data/corpus.txt

Things to consider:

- Uni/bi-grams: 
    - Different corpus?
    - Different ordering of words for feature selection (i.e., instead of raw frequency)
    - Better filtering of non-relevant words? (i.e., get rid of stop words, etc.)
    - Check out better tokenization :: nltk.download() will get us nltk.data.load('tokenizers/punkt/english.pickle')
- How to build a more general model using all of the entry sets, and not just learning on each set?

Try modeling individual graders
fix kaggle.py to be better

DATA EXPLORATION TODOs:
- output ranked in order of how badly we predict
- look at distribution of scores/grades
- Look at x/y plot of projected 1-dimensional feature vs grades for each grader
- FEATURE IDEA: What is the document similarity between the answer and the prompt???

LEARNING IDEAS:
cross validation framework to set SVM parameters. specify validation set, svm tries a few parameter settings and picks the best one on the validation data
non-linear kernel
numerical optimization of learning: save last 3 parameter vectors and objective scores, take a quadratic Newton-descent type step
when stochastic gradient descent is close to convergence, switch to a few iterations of gradient descent? newton's method?
anneal eta down to 0 as we converge

do feature selection by essay set

---

Features we get for free with nltk.

"RTE" (textual entailment)

def rte_features(rtepair):
    extractor = nltk.RTEFeatureExtractor(rtepair)
    features = {}
    features['word_overlap'] = len(extractor.overlap('word'))
    features['word_hyp_extra'] = len(extractor.hyp_extra('word'))
    features['ne_overlap'] = len(extractor.overlap('ne'))
    features['ne_hyp_extra'] = len(extractor.hyp_extra('ne'))
    return features

found at http://nltk.googlecode.com/svn/trunk/doc/book/ch06.html

----

Overall:
 - try lots of classifiers, then take a max vote between them. (or weighted max vote)
 - find the parameters that work best for each essay set, domain id pair.
 - with OTHER_DISTS, can we do anything with the traits?
