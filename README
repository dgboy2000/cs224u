To get Hunpos tagger to work:

* Download http://hunpos.googlecode.com/files/hunpos-1.0-macosx.tgz
* Extract the tar, and put the executables in ~/bin/

Install 'gensim':
$ wget http://pypi.python.org/packages/source/g/gensim/gensim-0.8.3.tar.gz
$ tar xzvf gensim-0.8.3.tar.gz
$ cd gensim-0.8.3
$ python setup.py test
$ sudo python setup.py install

To convert data to UTF-8:
iconv -f WINDOWS-1252 -t "UTF-8//IGNORE" training_set_rel3.tsv > training_set_rel3.utf8ignore.tsv

Install hunspell spellchecker:
1. Go to http://hunspell.sourceforge.net/
2. Download the source (top of page, or Source)
3. configure / make / make install

Installing mlpy:
$ sudo port install py27-gsl
$ wget http://sourceforge.net/projects/mlpy/files/mlpy%203.4.0/mlpy-3.4.0.tar.gz/download
$ tar -xvf mlpy-3.4.0.tar.gz
$ cd mlpy-3.4.0
$ sudo python setup.py install

Installing the python svmlight package:
$ hg clone https://bitbucket.org/wcauchois/pysvmlight
$ cd pysvmlight
$ python setup.py build
$ sudo python setup.py install
$ python examples/simple.py

Source of unigrams/bigrams (entire .uk domain):
  http://wacky.sslmit.unibo.it/doku.php?id=frequency_lists

Installing the python libsvm wrapper
$ cs learn/libsvm-3.11/python
$ make

Spell-correcting the datasets:
$ python
>>> from spelling.SpellCorrector import SpellCorrector
>>> sc = SpellCorrector()
>>> sc.correctEssaySets('data/c_train.utf8ignore.tsv', 'data/c_train.corrected.tsv')
    (repeat for each dataset file)
